# Key Architectural Decisions

### 4.1 Decision: OpenTofu + terraform-exec vs Native SDKs

**Context:** How to provision infrastructure - native cloud SDKs or Terraform/OpenTofu?

**Decision:** Use OpenTofu modules with terraform-exec Go library.

**Rationale:**

| Factor | Native SDKs | OpenTofu + terraform-exec |
|--------|-------------|---------------------------|
| **Development Speed** | Slower (write all SDK calls) | Faster (reuse modules) |
| **Code Volume** | High (verbose SDK calls) | Low (module composition) |
| **Community Resources** | Limited Go examples | Thousands of modules |
| **Provider Support** | SDK version dependencies | All Terraform providers |
| **Error Messages** | Direct from cloud APIs | Through Terraform layer |
| **Performance** | Fast (direct API calls) | Slower (plan/apply overhead) |
| **Debugging** | Easier (stack traces) | Harder (extra layer) |
| **State Management** | Custom (we build it) | Standard (Terraform state) |
| **Testing** | Mock cloud APIs | Mock Terraform (harder) |
| **Team Familiarity** | Requires cloud SDK knowledge | Terraform knowledge (common) |

**Conclusion:** For NIC, **OpenTofu + terraform-exec wins** because:
1. Faster time to market (reuse existing modules)
2. Larger team skillset overlap (Terraform is ubiquitous)
3. Proven patterns and modules already exist
4. Lower maintenance burden (community maintains modules)
5. Easier to contribute (Terraform is more familiar than cloud SDKs)

**Trade-off Accepted:** Slightly slower performance and indirect error messages are acceptable for a platform deployment tool (not latency-sensitive).

### 4.2 Decision: Unified Deployment (Not Staged)

**Context:** Old Nebari had 6+ stages (terraform-state, infrastructure, kubernetes-initialize, ingress, keycloak, etc.)

**Decision:** NIC deploys everything in one unified OpenTofu apply.

**Rationale:**
- Single Terraform root module with submodules
- Terraform handles dependency ordering (VPC → Cluster → K8s resources → ArgoCD)
- Faster deployment (no inter-stage waiting)
- Simpler state management (one Terraform state)
- Clearer error messages (Terraform dependency graph shows failures)

**Implementation:**
```hcl
# terraform/main.tf
module "vpc" {
  source = "./modules/aws/vpc"
  # ...
}

module "eks" {
  source = "./modules/aws/eks"
  vpc_id = module.vpc.vpc_id
  # ...
}

module "kubernetes_bootstrap" {
  source = "./modules/kubernetes"
  cluster_endpoint = module.eks.cluster_endpoint
  # ...
  depends_on = [module.eks]
}

module "argocd" {
  source = "./modules/argocd"
  # ...
  depends_on = [module.kubernetes_bootstrap]
}

module "foundational_apps" {
  source = "./modules/foundational-apps"
  # ...
  depends_on = [module.argocd]
}
```

### 4.3 Decision: Terraform State (Not Custom State)

**Context:** Need to track infrastructure state across deployments.

**Decision:** Use Terraform state with standard backends.

**Rationale:**
- Battle-tested state format
- Standard backends (S3, GCS, Azure Blob, Terraform Cloud)
- Built-in locking mechanisms
- Existing tooling (terraform state commands, atlantis, etc.)
- No need to build custom state management
- Familiar to operators

**State Backend Configuration:**
```hcl
# Generated by NIC from nebari-config.yaml
terraform {
  backend "s3" {
    bucket         = "nebari-prod-terraform-state"
    key            = "nic/terraform.tfstate"
    region         = "us-west-2"
    encrypt        = true
    dynamodb_table = "nebari-prod-terraform-locks"
  }
}
```

### 4.4 Decision: terraform-exec Library

**Context:** How to invoke OpenTofu from Go?

**Decision:** Use `github.com/hashicorp/terraform-exec` library.

**Rationale:**
- Official Terraform Go library
- Clean programmatic API
- Handles Terraform binary discovery
- Provides structured output parsing
- Supports all Terraform commands (init, plan, apply, destroy)
- Used by Terraform Cloud, Atlantis, other tools

**Example Usage:**
```go
import (
    "github.com/hashicorp/terraform-exec/tfexec"
)

func (p *TofuProvider) Deploy(ctx context.Context, config Config) error {
    ctx, span := tracer.Start(ctx, "TofuProvider.Deploy")
    defer span.End()

    // Initialize Terraform
    tf, err := tfexec.NewTerraform(p.workingDir, p.tofuPath)
    if err != nil {
        return fmt.Errorf("creating terraform executor: %w", err)
    }

    // Init
    slog.InfoContext(ctx, "initializing OpenTofu")
    if err := tf.Init(ctx); err != nil {
        return fmt.Errorf("terraform init: %w", err)
    }

    // Plan
    slog.InfoContext(ctx, "planning infrastructure changes")
    plan, err := tf.Plan(ctx)
    if err != nil {
        return fmt.Errorf("terraform plan: %w", err)
    }

    // Apply
    slog.InfoContext(ctx, "applying infrastructure changes")
    if err := tf.Apply(ctx); err != nil {
        return fmt.Errorf("terraform apply: %w", err)
    }

    slog.InfoContext(ctx, "infrastructure deployed successfully")
    return nil
}
```

### 4.5 Decision: ArgoCD for Foundational Software

**Context:** How to deploy and manage foundational software (Keycloak, LGTM, etc.)?

**Decision:** Deploy ArgoCD via Terraform Helm provider, then create ArgoCD Applications via Terraform kubernetes provider.

**Rationale:**
- ArgoCD deployed in same Terraform apply (atomic)
- ArgoCD Applications defined as Terraform resources
- Infrastructure as Code for entire stack
- GitOps benefits (declarative, version-controlled, self-healing)
- Terraform manages initial deployment, ArgoCD manages ongoing state

**Implementation:**
```hcl
# terraform/modules/argocd/main.tf
resource "helm_release" "argocd" {
  name       = "argocd"
  repository = "https://argoproj.github.io/argo-helm"
  chart      = "argo-cd"
  version    = var.argocd_version
  namespace  = "nebari-system"

  values = [templatefile("${path.module}/values.yaml", {
    domain = var.domain
  })]
}

# terraform/modules/foundational-apps/main.tf
resource "kubernetes_manifest" "cert_manager_app" {
  manifest = {
    apiVersion = "argoproj.io/v1alpha1"
    kind       = "Application"
    metadata = {
      name      = "cert-manager"
      namespace = "nebari-system"
    }
    spec = {
      project = "default"
      source = {
        repoURL        = var.foundational_repo_url
        path           = "cert-manager"
        targetRevision = "main"
      }
      destination = {
        server    = "https://kubernetes.default.svc"
        namespace = "cert-manager"
      }
      syncPolicy = {
        automated = {
          prune    = true
          selfHeal = true
        }
      }
    }
  }

  depends_on = [helm_release.argocd]
}
```

### 4.6 Decision: Nebari Kubernetes Operator

**Context:** Applications need to integrate with auth, o11y, and routing.

**Decision:** Build a Kubernetes operator that watches `nebari-application` CRDs and automates integration. Deploy operator via Terraform.

**Rationale:**
- Same as Native SDK edition (operator logic is independent of infrastructure provisioning)
- Reduces manual configuration (no more copy-paste YAML)
- Consistent integration across all apps
- Self-service for developers
- Native Kubernetes workflow

**Deployment:**
```hcl
# terraform/modules/foundational-apps/nebari-operator.tf
resource "kubernetes_manifest" "nebari_operator_app" {
  manifest = {
    apiVersion = "argoproj.io/v1alpha1"
    kind       = "Application"
    metadata = {
      name      = "nebari-operator"
      namespace = "nebari-system"
    }
    spec = {
      project = "default"
      source = {
        repoURL        = var.foundational_repo_url
        path           = "operator"
        targetRevision = "main"
      }
      destination = {
        server    = "https://kubernetes.default.svc"
        namespace = "nebari-system"
      }
      syncPolicy = {
        automated = {
          prune    = true
          selfHeal = true
        }
      }
    }
  }

  depends_on = [
    kubernetes_manifest.keycloak_app,
    kubernetes_manifest.grafana_app,
    kubernetes_manifest.envoy_gateway_app
  ]
}
```

### 4.7 Decision: OpenTelemetry Throughout

**Context:** Need comprehensive observability for NIC itself.

**Decision:** Instrument all NIC Go code with OpenTelemetry (traces, metrics, logs).

**Rationale:**
- Same as Native SDK edition
- Debugging deployment issues
- Performance monitoring
- Vendor-neutral (can export to any backend)
- Unified observability story (NIC uses same stack it deploys)

**Implementation:**
- Wrap terraform-exec calls in trace spans
- Capture Terraform output and log it with trace context
- Custom metrics for Terraform operations (plan duration, apply duration, resource counts)
- Export to deployed LGTM stack

---
